# 6.1 间隔与支持向量
* 通过线性方程划分超平面 w**T * x + b = 0
* 样本中任意点x，到超平面(w,b) 的距离为：r = abs(w**T * x + b) / ||w||
* (w, b)能将训练样本正确分类，则
    * w**T * x + b >= +1, y = +1
    * w**T * x + b <= -1, y = -1
* 距离超平面最近的几个样本点，被称为“支持向量”
* 两个异类支持向量道超平面的距离之和为：r = 2/||w||，称为“间隔”
* 找最大间隔
```
max(w, b) 2/||w||
=> max(||w||**-1)
=> min(||w||**2)
=> min(w,b) 1/2 * ||w||**2
```
# 6.2 对偶问题
* 使用拉格朗日乘子法
```
L(w, b, a) = 1/2 * ||w|| ** 2 + SUM(i=1,i<=m, a(1-y(w**T*x + b) ) )
# 对w和b的偏道为零可得
w = SUM(i=1, i<=m, a * y * x )
0 = SUM(i=1, i<=m, a * y)
```
* 训练完成后，大部分训练样本都不需要保留，最终模型仅与支持向量有关

# 6.3 核函数
* 现实中异或问题，就不能线形可分
* 映射到更高维再划分
* 核函数k(xi,xj): 表示xi与xj在特征空间的内积等于它们在原始样本空间中通过函数k计算的结果
* 核函数选择，称为支持向量机的最大变数